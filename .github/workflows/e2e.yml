name: End-to-End Testing

on:
  push:
    branches: [main, develop]
    paths:
      - "src/**"
      - "tests/e2e/**"
      - ".github/workflows/e2e.yml"
  pull_request:
    branches: [main, develop]
    paths:
      - "src/**"
      - "tests/e2e/**"
  schedule:
    - cron: "0 0 * * *" # Daily at midnight
  workflow_dispatch: # Allow manual trigger
    inputs:
      test_suite:
        description: "E2E test suite to run"
        required: true
        type: choice
        options:
          - all
          - bot-commands
          - game-features
          - media-playback
          - user-interactions

jobs:
  setup:
    name: Setup Test Environment
    runs-on: ubuntu-latest
    outputs:
      test_id: ${{ steps.setup.outputs.test_id }}

    steps:
      - name: Generate test ID
        id: setup
        run: |
          echo "test_id=$(date +%Y%m%d_%H%M%S)" >> $GITHUB_OUTPUT

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.8"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install pytest-playwright pytest-xdist pytest-rerunfailures

      - name: Install Playwright
        run: |
          playwright install
          playwright install-deps

  test-bot:
    name: Bot Command Tests
    needs: setup
    if: github.event.inputs.test_suite == 'bot-commands' || github.event.inputs.test_suite == 'all' || github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    services:
      redis:
        image: redis:6-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Run bot command tests
        env:
          DISCORD_TOKEN: ${{ secrets.TEST_DISCORD_TOKEN }}
          TEST_CHANNEL_ID: ${{ secrets.TEST_CHANNEL_ID }}
        run: |
          pytest tests/e2e/test_bot_commands.py \
            -v --log-cli-level=INFO \
            --reruns 3 --reruns-delay 30

  test-game:
    name: Game Feature Tests
    needs: setup
    if: github.event.inputs.test_suite == 'game-features' || github.event.inputs.test_suite == 'all' || github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Run game feature tests
        env:
          OSRS_API_KEY: ${{ secrets.OSRS_API_KEY }}
        run: |
          pytest tests/e2e/test_game_features.py \
            -v --log-cli-level=INFO \
            --reruns 3 --reruns-delay 30

  test-media:
    name: Media Playback Tests
    needs: setup
    if: github.event.inputs.test_suite == 'media-playback' || github.event.inputs.test_suite == 'all' || github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Run media playback tests
        env:
          DISCORD_TOKEN: ${{ secrets.TEST_DISCORD_TOKEN }}
          TEST_VOICE_CHANNEL: ${{ secrets.TEST_VOICE_CHANNEL }}
        run: |
          pytest tests/e2e/test_media_playback.py \
            -v --log-cli-level=INFO \
            --reruns 3 --reruns-delay 30

  test-user:
    name: User Interaction Tests
    needs: setup
    if: github.event.inputs.test_suite == 'user-interactions' || github.event.inputs.test_suite == 'all' || github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Run user interaction tests
        run: |
          pytest tests/e2e/test_user_interactions.py \
            -v --log-cli-level=INFO \
            --browser chromium \
            --headed \
            --screenshot on

  record-video:
    name: Record Test Video
    needs: [setup, test-bot, test-game, test-media, test-user]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Record test session
        run: |
          playwright codegen --target python -o test-recording.py \
            --viewport-size=1280,720 \
            --save-storage=auth.json

      - name: Upload test artifacts
        uses: actions/upload-artifact@v3
        with:
          name: e2e-test-artifacts
          path: |
            test-recording.py
            auth.json
            test-results/
            screenshots/

  report:
    name: Generate Report
    needs: [setup, test-bot, test-game, test-media, test-user]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Generate test report
        run: |
          {
            echo "# E2E Test Report"
            echo "## Test ID: ${{ needs.setup.outputs.test_id }}"
            echo "## Test Results"
            echo "- Bot Commands: ${{ needs.test-bot.result }}"
            echo "- Game Features: ${{ needs.test-game.result }}"
            echo "- Media Playback: ${{ needs.test-media.result }}"
            echo "- User Interactions: ${{ needs.test-user.result }}"
            
            echo "## Test Coverage"
            echo "\`\`\`"
            coverage report
            echo "\`\`\`"
            
            echo "## Screenshots"
            echo "Test screenshots are available in the artifacts."
            
            echo "## Video Recording"
            echo "Test recording is available in the artifacts."
          } > e2e-report.md

      - name: Create issue for failures
        if: contains(needs.*.result, 'failure')
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('e2e-report.md', 'utf8');
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '❌ E2E Tests Failed',
              body: report,
              labels: ['e2e', 'test-failure']
            });

      - name: Update metrics
        run: |
          {
            echo "e2e_tests_total $(date +%s)"
            echo "e2e_tests_failed $(echo '${{ needs.*.result }}' | grep -c failure || true)"
          } > e2e_metrics.txt

          curl -X POST ${{ secrets.PROMETHEUS_PUSHGATEWAY }}/metrics/job/e2e_testing \
            --data-binary "@e2e_metrics.txt"

      - name: Notify status
        uses: sarisia/actions-status-discord@v1
        with:
          webhook: ${{ secrets.DISCORD_WEBHOOK }}
          title: "E2E Tests Complete"
          description: |
            Test ID: ${{ needs.setup.outputs.test_id }}
            Status: ${{ contains(needs.*.result, 'failure') && '❌ Failed' || '✅ Passed' }}

            Check the workflow run for detailed results.
          color: ${{ contains(needs.*.result, 'failure') && '0xff0000' || '0x00ff00' }}
          username: "E2E Test Bot"
