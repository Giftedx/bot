name: Accessibility Testing

on:
  push:
    branches: [main, develop]
    paths:
      - "src/**"
      - "tests/accessibility/**"
      - ".github/workflows/accessibility.yml"
  pull_request:
    branches: [main, develop]
    paths:
      - "src/**"
      - "tests/accessibility/**"
  schedule:
    - cron: "0 0 * * 1" # Weekly on Monday
  workflow_dispatch: # Allow manual trigger
    inputs:
      test_scope:
        description: "Accessibility test scope"
        required: true
        type: choice
        options:
          - all
          - commands
          - messages
          - interfaces
          - documentation

jobs:
  setup:
    name: Setup Test Environment
    runs-on: ubuntu-latest
    outputs:
      test_id: ${{ steps.setup.outputs.test_id }}

    steps:
      - name: Generate test ID
        id: setup
        run: |
          echo "test_id=$(date +%Y%m%d_%H%M%S)" >> $GITHUB_OUTPUT

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.8"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install axe-selenium-python pa11y-python wcag-checker

  test-commands:
    name: Command Accessibility
    needs: setup
    if: github.event.inputs.test_scope == 'commands' || github.event.inputs.test_scope == 'all' || github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Test command help messages
        run: |
          python tests/accessibility/test_command_help.py \
            --output command_help_report.json

      - name: Test command responses
        run: |
          python tests/accessibility/test_command_responses.py \
            --output command_responses_report.json

      - name: Analyze results
        run: |
          python scripts/accessibility/analyze_commands.py \
            --help-report command_help_report.json \
            --responses-report command_responses_report.json \
            --output command_analysis.md

  test-messages:
    name: Message Accessibility
    needs: setup
    if: github.event.inputs.test_scope == 'messages' || github.event.inputs.test_scope == 'all' || github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Test message formatting
        run: |
          python tests/accessibility/test_message_formatting.py \
            --output message_format_report.json

      - name: Test message readability
        run: |
          python tests/accessibility/test_message_readability.py \
            --output message_readability_report.json

      - name: Analyze results
        run: |
          python scripts/accessibility/analyze_messages.py \
            --format-report message_format_report.json \
            --readability-report message_readability_report.json \
            --output message_analysis.md

  test-interfaces:
    name: Interface Accessibility
    needs: setup
    if: github.event.inputs.test_scope == 'interfaces' || github.event.inputs.test_scope == 'all' || github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Install browser
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser

      - name: Test web interfaces
        run: |
          pa11y-ci --config .pa11yci

      - name: Run axe analysis
        run: |
          python tests/accessibility/test_interfaces_axe.py \
            --output interface_axe_report.json

      - name: Check WCAG compliance
        run: |
          python tests/accessibility/test_wcag_compliance.py \
            --output wcag_report.json

      - name: Analyze results
        run: |
          python scripts/accessibility/analyze_interfaces.py \
            --pa11y-report pa11y_report.json \
            --axe-report interface_axe_report.json \
            --wcag-report wcag_report.json \
            --output interface_analysis.md

  test-documentation:
    name: Documentation Accessibility
    needs: setup
    if: github.event.inputs.test_scope == 'documentation' || github.event.inputs.test_scope == 'all' || github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Test documentation accessibility
        run: |
          python tests/accessibility/test_documentation.py \
            --output documentation_report.json

      - name: Check markdown accessibility
        run: |
          python tests/accessibility/test_markdown_a11y.py \
            --output markdown_report.json

      - name: Analyze results
        run: |
          python scripts/accessibility/analyze_documentation.py \
            --docs-report documentation_report.json \
            --markdown-report markdown_report.json \
            --output documentation_analysis.md

  report:
    name: Generate Report
    needs:
      [setup, test-commands, test-messages, test-interfaces, test-documentation]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Combine reports
        run: |
          {
            echo "# Accessibility Test Report"
            echo "## Test ID: ${{ needs.setup.outputs.test_id }}"
            
            echo "## Command Accessibility"
            cat command_analysis.md
            
            echo "## Message Accessibility"
            cat message_analysis.md
            
            echo "## Interface Accessibility"
            cat interface_analysis.md
            
            echo "## Documentation Accessibility"
            cat documentation_analysis.md
            
            echo "## Summary"
            echo "- Commands: ${{ needs.test-commands.result }}"
            echo "- Messages: ${{ needs.test-messages.result }}"
            echo "- Interfaces: ${{ needs.test-interfaces.result }}"
            echo "- Documentation: ${{ needs.test-documentation.result }}"
          } > accessibility-report.md

      - name: Create issue for violations
        if: contains(needs.*.result, 'failure')
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('accessibility-report.md', 'utf8');
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '♿ Accessibility Issues Detected',
              body: report,
              labels: ['accessibility', 'bug']
            });

      - name: Update metrics
        run: |
          {
            echo "accessibility_tests_total $(date +%s)"
            echo "accessibility_violations $(echo '${{ needs.*.result }}' | grep -c failure || true)"
          } > accessibility_metrics.txt

          curl -X POST ${{ secrets.PROMETHEUS_PUSHGATEWAY }}/metrics/job/accessibility_testing \
            --data-binary "@accessibility_metrics.txt"

      - name: Notify status
        uses: sarisia/actions-status-discord@v1
        with:
          webhook: ${{ secrets.DISCORD_WEBHOOK }}
          title: "Accessibility Tests Complete"
          description: |
            Test ID: ${{ needs.setup.outputs.test_id }}
            Status: ${{ contains(needs.*.result, 'failure') && '❌ Issues Found' || '✅ All Tests Passed' }}

            Check the workflow run for detailed results.
          color: ${{ contains(needs.*.result, 'failure') && '0xff0000' || '0x00ff00' }}
          username: "Accessibility Bot"
