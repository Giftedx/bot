name: Stress Testing

on:
  schedule:
    - cron: "0 0 * * 4" # Weekly on Thursday
  workflow_dispatch: # Allow manual trigger
    inputs:
      test_duration:
        description: "Test duration in minutes"
        required: true
        type: number
        default: 30
      concurrent_users:
        description: "Number of concurrent users"
        required: true
        type: number
        default: 1000
      test_type:
        description: "Type of stress test"
        required: true
        type: choice
        options:
          - spike
          - sustained
          - gradual
          - chaos

jobs:
  prepare:
    name: Prepare Test Environment
    runs-on: ubuntu-latest
    outputs:
      test_id: ${{ steps.setup.outputs.test_id }}

    steps:
      - name: Generate test ID
        id: setup
        run: |
          echo "test_id=$(date +%Y%m%d_%H%M%S)" >> $GITHUB_OUTPUT

      - name: Configure test parameters
        run: |
          {
            echo "DURATION=${{ github.event.inputs.test_duration || 30 }}"
            echo "USERS=${{ github.event.inputs.concurrent_users || 1000 }}"
            echo "TYPE=${{ github.event.inputs.test_type || 'sustained' }}"
          } > test-config.env

  load-test:
    name: Load Generation
    needs: prepare
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.8"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install locust k6 artillery

      - name: Run spike test
        if: github.event.inputs.test_type == 'spike' || github.event.inputs.test_type == 'chaos'
        run: |
          locust \
            --headless \
            --users ${{ github.event.inputs.concurrent_users || 1000 }} \
            --spawn-rate 100 \
            --run-time ${{ github.event.inputs.test_duration || 30 }}m \
            --csv spike_results \
            -f tests/stress/spike_test.py

      - name: Run sustained load test
        if: github.event.inputs.test_type == 'sustained' || github.event.inputs.test_type == 'chaos'
        run: |
          k6 run \
            --vus ${{ github.event.inputs.concurrent_users || 1000 }} \
            --duration ${{ github.event.inputs.test_duration || 30 }}m \
            tests/stress/sustained_test.js

      - name: Run gradual increase test
        if: github.event.inputs.test_type == 'gradual' || github.event.inputs.test_type == 'chaos'
        run: |
          artillery run \
            --output gradual_results.json \
            tests/stress/gradual_test.yml

      - name: Generate load report
        run: |
          {
            echo "# Load Test Results"
            echo "## Test Configuration"
            echo "- Duration: ${{ github.event.inputs.test_duration || 30 }} minutes"
            echo "- Users: ${{ github.event.inputs.concurrent_users || 1000 }}"
            echo "- Type: ${{ github.event.inputs.test_type || 'sustained' }}"
            
            echo "## Results"
            if [ -f "spike_results_stats.csv" ]; then
              echo "### Spike Test"
              cat spike_results_stats.csv
            fi
            
            if [ -f "k6_results.json" ]; then
              echo "### Sustained Load"
              cat k6_results.json | jq .metrics
            fi
            
            if [ -f "gradual_results.json" ]; then
              echo "### Gradual Increase"
              cat gradual_results.json | jq .aggregate
            fi
          } > load-report.md

  monitor:
    name: System Monitoring
    needs: [prepare, load-test]
    runs-on: ubuntu-latest

    steps:
      - name: Monitor system metrics
        run: |
          python scripts/stress/monitor_system.py \
            --duration ${{ github.event.inputs.test_duration || 30 }} \
            --output system_metrics.json

      - name: Monitor application metrics
        run: |
          python scripts/stress/monitor_application.py \
            --duration ${{ github.event.inputs.test_duration || 30 }} \
            --output app_metrics.json

      - name: Generate monitoring report
        run: |
          {
            echo "# System Monitoring Report"
            echo "## System Metrics"
            cat system_metrics.json | jq -r '.[] | "- " + .metric + ": " + (.value | tostring)'
            echo "## Application Metrics"
            cat app_metrics.json | jq -r '.[] | "- " + .metric + ": " + (.value | tostring)'
          } > monitoring-report.md

  analyze:
    name: Performance Analysis
    needs: [prepare, load-test, monitor]
    runs-on: ubuntu-latest

    steps:
      - name: Analyze response times
        run: |
          python scripts/stress/analyze_response_times.py \
            --load-data load-report.md \
            --output response_analysis.json

      - name: Analyze resource usage
        run: |
          python scripts/stress/analyze_resources.py \
            --metrics monitoring-report.md \
            --output resource_analysis.json

      - name: Analyze bottlenecks
        run: |
          python scripts/stress/analyze_bottlenecks.py \
            --response-data response_analysis.json \
            --resource-data resource_analysis.json \
            --output bottleneck_analysis.json

      - name: Generate analysis report
        run: |
          {
            echo "# Performance Analysis Report"
            echo "## Response Time Analysis"
            cat response_analysis.json | jq -r '.findings[] | "- " + .'
            echo "## Resource Usage Analysis"
            cat resource_analysis.json | jq -r '.findings[] | "- " + .'
            echo "## Bottleneck Analysis"
            cat bottleneck_analysis.json | jq -r '.findings[] | "- " + .'
          } > analysis-report.md

  report:
    name: Generate Report
    needs: [prepare, load-test, monitor, analyze]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Combine reports
        run: |
          {
            echo "# Stress Test Report"
            echo "Test ID: ${{ needs.prepare.outputs.test_id }}"
            
            echo "## Load Testing"
            cat load-report.md
            
            echo "## System Monitoring"
            cat monitoring-report.md
            
            echo "## Performance Analysis"
            cat analysis-report.md
            
            echo "## Recommendations"
            python scripts/stress/generate_recommendations.py \
              --analysis analysis-report.md \
              --output recommendations.md
            cat recommendations.md
          } > stress-report.md

      - name: Create issue for findings
        if: contains(needs.*.result, 'failure') || github.event_name == 'schedule'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('stress-report.md', 'utf8');
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸ”¥ Stress Test Results',
              body: report,
              labels: ['performance', 'stress-test']
            });

      - name: Update metrics
        run: |
          {
            echo "stress_test_completion $(date +%s)"
            echo "performance_score $(python scripts/stress/calculate_score.py analysis-report.md)"
          } > stress_metrics.txt

          curl -X POST ${{ secrets.PROMETHEUS_PUSHGATEWAY }}/metrics/job/stress_testing \
            --data-binary "@stress_metrics.txt"

      - name: Notify team
        uses: sarisia/actions-status-discord@v1
        with:
          webhook: ${{ secrets.DISCORD_WEBHOOK }}
          title: "Stress Test Complete"
          description: |
            Test ID: ${{ needs.prepare.outputs.test_id }}
            Type: ${{ github.event.inputs.test_type || 'sustained' }}
            Duration: ${{ github.event.inputs.test_duration || 30 }} minutes
            Users: ${{ github.event.inputs.concurrent_users || 1000 }}

            Check the workflow run for detailed results.
          color: ${{ contains(needs.*.result, 'failure') && '0xff0000' || '0x00ff00' }}
          username: "Stress Test Bot"
