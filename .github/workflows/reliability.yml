name: Reliability Testing

on:
  schedule:
    - cron: "0 0 * * 6" # Weekly on Saturday
  workflow_dispatch: # Allow manual trigger
    inputs:
      test_type:
        description: "Type of reliability test"
        required: true
        type: choice
        options:
          - all
          - stability
          - durability
          - availability
          - fault-tolerance
      duration:
        description: "Test duration in hours"
        required: true
        type: number
        default: 24

jobs:
  prepare:
    name: Prepare Test Environment
    runs-on: ubuntu-latest
    outputs:
      test_id: ${{ steps.setup.outputs.test_id }}

    steps:
      - name: Generate test ID
        id: setup
        run: |
          echo "test_id=$(date +%Y%m%d_%H%M%S)" >> $GITHUB_OUTPUT

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.8"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install pytest-timeout pytest-reliability fault-injection reliability-metrics

  stability:
    name: Stability Testing
    needs: prepare
    if: github.event.inputs.test_type == 'stability' || github.event.inputs.test_type == 'all'
    runs-on: ubuntu-latest

    steps:
      - name: Run long-term stability test
        run: |
          python scripts/reliability/test_stability.py \
            --duration ${{ github.event.inputs.duration || 24 }} \
            --output stability_results.json

      - name: Monitor resource usage
        run: |
          python scripts/reliability/monitor_resources.py \
            --duration ${{ github.event.inputs.duration || 24 }} \
            --output resource_usage.json

      - name: Generate stability report
        run: |
          {
            echo "# Stability Test Report"
            echo "## Test Results"
            cat stability_results.json | jq -r '.results[] | "- " + .'
            echo "## Resource Usage"
            cat resource_usage.json | jq -r '.usage[] | "- " + .'
          } > stability-report.md

  durability:
    name: Durability Testing
    needs: prepare
    if: github.event.inputs.test_type == 'durability' || github.event.inputs.test_type == 'all'
    runs-on: ubuntu-latest

    steps:
      - name: Run continuous operation test
        run: |
          python scripts/reliability/test_durability.py \
            --duration ${{ github.event.inputs.duration || 24 }} \
            --output durability_results.json

      - name: Test data persistence
        run: |
          python scripts/reliability/test_persistence.py \
            --duration ${{ github.event.inputs.duration || 24 }} \
            --output persistence_results.json

      - name: Generate durability report
        run: |
          {
            echo "# Durability Test Report"
            echo "## Operation Results"
            cat durability_results.json | jq -r '.results[] | "- " + .'
            echo "## Data Persistence"
            cat persistence_results.json | jq -r '.results[] | "- " + .'
          } > durability-report.md

  availability:
    name: Availability Testing
    needs: prepare
    if: github.event.inputs.test_type == 'availability' || github.event.inputs.test_type == 'all'
    runs-on: ubuntu-latest

    steps:
      - name: Test service uptime
        run: |
          python scripts/reliability/test_uptime.py \
            --duration ${{ github.event.inputs.duration || 24 }} \
            --output uptime_results.json

      - name: Test response times
        run: |
          python scripts/reliability/test_response.py \
            --duration ${{ github.event.inputs.duration || 24 }} \
            --output response_results.json

      - name: Generate availability report
        run: |
          {
            echo "# Availability Test Report"
            echo "## Uptime Results"
            cat uptime_results.json | jq -r '.results[] | "- " + .'
            echo "## Response Times"
            cat response_results.json | jq -r '.results[] | "- " + .'
          } > availability-report.md

  fault-tolerance:
    name: Fault Tolerance Testing
    needs: prepare
    if: github.event.inputs.test_type == 'fault-tolerance' || github.event.inputs.test_type == 'all'
    runs-on: ubuntu-latest

    steps:
      - name: Inject faults
        run: |
          python scripts/reliability/inject_faults.py \
            --duration ${{ github.event.inputs.duration || 24 }} \
            --output fault_injection.json

      - name: Test recovery
        run: |
          python scripts/reliability/test_recovery.py \
            --duration ${{ github.event.inputs.duration || 24 }} \
            --output recovery_results.json

      - name: Generate fault tolerance report
        run: |
          {
            echo "# Fault Tolerance Report"
            echo "## Fault Injection Results"
            cat fault_injection.json | jq -r '.results[] | "- " + .'
            echo "## Recovery Results"
            cat recovery_results.json | jq -r '.results[] | "- " + .'
          } > fault-tolerance-report.md

  analyze:
    name: Analyze Results
    needs: [prepare, stability, durability, availability, fault-tolerance]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Calculate reliability metrics
        run: |
          python scripts/reliability/calculate_metrics.py \
            --test-id ${{ needs.prepare.outputs.test_id }} \
            --output reliability_metrics.json

      - name: Analyze trends
        run: |
          python scripts/reliability/analyze_trends.py \
            --test-id ${{ needs.prepare.outputs.test_id }} \
            --output trend_analysis.json

      - name: Generate analysis report
        run: |
          {
            echo "# Reliability Analysis Report"
            echo "## Reliability Metrics"
            cat reliability_metrics.json | jq -r '.metrics[] | "- " + .'
            echo "## Trend Analysis"
            cat trend_analysis.json | jq -r '.trends[] | "- " + .'
          } > analysis-report.md

  report:
    name: Generate Report
    needs:
      [prepare, stability, durability, availability, fault-tolerance, analyze]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Combine reports
        run: |
          {
            echo "# Reliability Test Report"
            echo "Test ID: ${{ needs.prepare.outputs.test_id }}"
            echo "Duration: ${{ github.event.inputs.duration || 24 }} hours"
            
            echo "## Stability Testing"
            cat stability-report.md
            
            echo "## Durability Testing"
            cat durability-report.md
            
            echo "## Availability Testing"
            cat availability-report.md
            
            echo "## Fault Tolerance Testing"
            cat fault-tolerance-report.md
            
            echo "## Analysis"
            cat analysis-report.md
            
            echo "## Recommendations"
            python scripts/reliability/generate_recommendations.py \
              --analysis analysis-report.md \
              --output recommendations.md
            cat recommendations.md
          } > reliability-report.md

      - name: Create issue for failures
        if: contains(needs.*.result, 'failure')
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('reliability-report.md', 'utf8');
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '⚠️ Reliability Issues Detected',
              body: report,
              labels: ['reliability', 'bug']
            });

      - name: Update metrics
        run: |
          {
            echo "reliability_completion $(date +%s)"
            echo "reliability_score $(python scripts/reliability/calculate_score.py analysis-report.md)"
          } > reliability_metrics.txt

          curl -X POST ${{ secrets.PROMETHEUS_PUSHGATEWAY }}/metrics/job/reliability_testing \
            --data-binary "@reliability_metrics.txt"

      - name: Notify team
        uses: sarisia/actions-status-discord@v1
        with:
          webhook: ${{ secrets.DISCORD_WEBHOOK }}
          title: "Reliability Tests Complete"
          description: |
            Test ID: ${{ needs.prepare.outputs.test_id }}
            Duration: ${{ github.event.inputs.duration || 24 }} hours

            Check the workflow run for detailed results.
          color: ${{ contains(needs.*.result, 'failure') && '0xff0000' || '0x00ff00' }}
          username: "Reliability Bot"
